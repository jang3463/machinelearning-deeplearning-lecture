{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "텍스트 다루기.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwN3T9uCv89SxczrBuzI3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jang3463/machinelearning-deeplearning-lecture/blob/main/%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%8B%A4%EB%A3%A8%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mljgb-Vo8Cas"
      },
      "source": [
        "# Tokenization (토큰화) 이론\r\n",
        "\r\n",
        "텍스트에서 어디까지가 문장이고, 무엇이 단어인지를 알려주는 것을 의미\r\n",
        "* 문장 토큰화( Sentence Tokenization )\r\n",
        "* 단어 토큰화 ( Word Tokenization )\r\n",
        "* subword 토큰화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD7uPPCP8ty0"
      },
      "source": [
        "## English Tokenization\r\n",
        "띄어쓰기 및 온점을 이용해 단어 및 문장에 대한 토큰화를 손쉽게 진행할 수 있다.(?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzgDy-P4w4w"
      },
      "source": [
        "sample_text=\"I never thought through love we'd be. Making one as lovely as she. But isn't she lovely made from love.\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiYIRdG58xiz"
      },
      "source": [
        "문장 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SiN_MLo6KZ-",
        "outputId": "2570d505-fd97-4605-ee15-59ea6eca48e5"
      },
      "source": [
        "# 단순하게 온점과 공백을 이용해서 잘라내기\r\n",
        "tokenized_sentence = sample_text.split('. ')\r\n",
        "tokenized_sentence"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I never thought through love we'd be\",\n",
              " 'Making one as lovely as she',\n",
              " \"But isn't she lovely made from love.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYaoDmI69CEo"
      },
      "source": [
        "단어 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI4xwi-e6Khd",
        "outputId": "21b035b1-fab3-47ed-c8df-5d6511b2adab"
      },
      "source": [
        "tokenized_word = sample_text.split()\r\n",
        "tokenized_word"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'never',\n",
              " 'thought',\n",
              " 'through',\n",
              " 'love',\n",
              " \"we'd\",\n",
              " 'be.',\n",
              " 'Making',\n",
              " 'one',\n",
              " 'as',\n",
              " 'lovely',\n",
              " 'as',\n",
              " 'she.',\n",
              " 'But',\n",
              " \"isn't\",\n",
              " 'she',\n",
              " 'lovely',\n",
              " 'made',\n",
              " 'from',\n",
              " 'love.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ubyAJlK9j1a"
      },
      "source": [
        "## 띄어쓰기(공백)로만 영어 문장 내 단어를 구분할 때의 문제점\r\n",
        "\r\n",
        "* We're Avengers!! : `[We're, Avengers!!]`\r\n",
        "* We are Avengers!! : `[We, are, Avengers!!]`\r\n",
        "* We are Avengers : `[We, are, Avengers]`\r\n",
        "\r\n",
        "단순하게 공백으로만 토큰화를 수행하면, 사람은 같은 문장이라는 것을 인지할 수 있으나, 하지만 기계는 위 세 문장이 다른 문장이라고 판단.\r\n",
        "\r\n",
        "### 그럼 특수문자를 제거하면?\r\n",
        "* `[We, re, Avengers]`\r\n",
        "* `[We, are, Avengers]`\r\n",
        "* `[We, are, AVengers]`\r\n",
        "\r\n",
        "특수문자가 중요한 의미를 가지는 경우에도 특수문자를 제거하면?\r\n",
        "* $12.45 : `[12, 45]`\r\n",
        "* Mr. So : `[Mr, So]`\r\n",
        "* Mrs. Kim : `[Mrs, Kim]`\r\n",
        "* 192.168.0.1 : `[192, 168, 0, 1]`\r\n",
        "* Ph.D : `[Ph, D]`\r\n",
        "\r\n",
        "특수문자가 중요한 역할을 하는 경우에는 별로 효용적이지 못한 것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0ndPOzY_T2S"
      },
      "source": [
        "## 미리 준비된 영어단어 토크나이져 준비 하기\r\n",
        "* TreebankWordTokenizer 패키지\r\n",
        " * 영어 표준 토큰화 규격을 따라간다.\r\n",
        " * Penn Treebank Tokenization 규칙\r\n",
        "\r\n",
        "* TreebankWordTokenizer 규칙\r\n",
        " * 하이푼으로 구성된 단어는 하나의 단어로 유지\r\n",
        " * doesn't 같이 어포스트로피로 '접어'가 함께하는 단어는 따로 분리\r\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzER_AIt_ir7"
      },
      "source": [
        "## 한국어 토큰화가 어려운 이유\r\n",
        "1. 한국어는 교착어이다.\r\n",
        "2. 한국어는 띄어쓰기가 잘 지켜지지 않는다.\r\n",
        "3. 한국어는 주어생략이 가능하고, 어순도 중요하지 않다.\r\n",
        "4. 한자어라는 특성상 하나의 음절도 다른 의미를 갖는다.\r\n",
        "\r\n",
        "### 교착어\r\n",
        "실질적인 의미를 가지는 어간에 조사나 어미와 같은 **문법 형태소**가 결합하여 문법적인 기능이 부여되는 언어\r\n",
        "\r\n",
        "> **핸드폰이** 바닥에 떨어져서, **핸드폰을** 새롭게 샀다. **핸드폰은** 다 부서졌다.\r\n",
        "\r\n",
        "### 띄어쓰기 문제\r\n",
        "> 이렇게띄어쓰기를하지않아도일단은잘읽을수있어요\r\n",
        "\r\n",
        "> yousugaryespleasewouldyoucomeandputitdownonme\r\n",
        "\r\n",
        "한국어와 다르게 영어는 띄어쓰기가 지켜지지 않으면 읽기가 어렵기 때문에 띄어쓰기에 엄격한 편이다.<br/>한국어 띄어쓰기 검사 피키지로 `ko-spacing`이나 `py-hanspell` 패키지를 사용하면 된다.\r\n",
        "\r\n",
        "### 주어 생략 및 어순 문제\r\n",
        "1. 나는 운동을 했어. 체육관에서\r\n",
        "2. 나는 체육관에서 운동을 했어.\r\n",
        "3. 체육관에서 운동했어.\r\n",
        "4. 나는 운동을 체육관에서 했어.\r\n",
        "\r\n",
        "### 한자어라는 특성 때문에 하나의 음절이 다른 의미를 갖는다.\r\n",
        "1. 배 라는 하나의 단어는 사람의 배, 타는 배, 먹는 배\r\n",
        "2. 한국에도 한국 한 / 나라 국 으로 이루어진 한자어 조합이다ㅣ.\r\n",
        " * 한 : 숫자 1, 하나를 의미하는지...\r\n",
        " * 국 : 먹는 국인지, 나라 국인지....\r\n",
        "\r\n",
        "\r\n",
        "한국어 형태소 분석을 쉽게 하기 위해 konlypy 패키지 활용\r\n",
        "```\r\n",
        " 공통적으로 Java가 설치 되어 있어야 한다.!!\r\n",
        "\r\n",
        " jupyter notebook : pip install konlpy \r\n",
        " google colab : !pip install konlpy\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOymye8x6Knt"
      },
      "source": [
        "#pip install konlpy"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb63B7-lCc3H"
      },
      "source": [
        "### Mecab\r\n",
        "\r\n",
        "실무에서 가장 많이 쓰이는 형태소 분석기. 맥이나 리눅스에서는 설치도 잘 되고 잘 돌아가는데, 윈도우즈에서는 절대 안돌아가요\r\n",
        "\r\n",
        "설치시간이 오래 걸리니까 미리 다운 받아 주세요 ( 다음 시간 수업 전에 미리 다운 받아 놓을 것 )\r\n",
        "\r\n",
        "```\r\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\r\n",
        "%cd Mecab-ko-for-Google-Colab\r\n",
        "!bash install_mecab-ko_on_colab190912.sh\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDjvHTUJ6Kt2"
      },
      "source": [
        "# !git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\r\n",
        "# %cd Mecab-ko-for-Google-Colab\r\n",
        "# !bash install_mecab-ko_on_colab190912.sh\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96CD2uppH_9y"
      },
      "source": [
        "### Twitter(Okt), 꼬꼬마(KKma), 코모란(Komoran), 한나눔(Hannanum)\r\n",
        "속도가 Mecab이나 카카오에서 개발한 Khaii 보다 느리지만 각각의 장단점이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVWlxKs8Jc8g"
      },
      "source": [
        "## 영어와 한국어 공통으로 처리해야 할 Cleaning (정제), Normalization(정규화)\r\n",
        "\r\n",
        "### 정제란?\r\n",
        "* **불필요한 데이터를 제거하는 것**\r\n",
        "* 텍스트 중간중간에 껴있는 숫자, 특수기호를 제거하는 작업\r\n",
        "* 한국어 같은 경우에는 은, 는, 이, 가 등의 불용어 처리(stopword)를 제거 하는 것\r\n",
        "* 영어의 경우에는 at, is, am, the 등을 제거 하는 것\r\n",
        "* 텍스트의 인코딩 문제를 해결하는 것\r\n",
        " * 인코딩 문제 : 예를 들어 텍스트 인코딩 방식이 EUC-KR로 되어 있는데, 지금 개발 환경은 UTF-8이라면 텍스트가 다 깨지는 현상\r\n",
        "* 길이가 짧은 단어들을 제거 하는 것 ( 선택적 )\r\n",
        "* 등장 빈도가 적은 단어 제거\r\n",
        "\r\n",
        "### 정규화란?\r\n",
        "* **문장의 복잡도를 줄여주는 과정**\r\n",
        "* 같은 의미를 가지고 있는 여러 단어를 하나로 통합하는 작업\r\n",
        "* 영어의 경우 lemmatization\r\n",
        " * am, are, were, was : `be`\r\n",
        " * has, had : `have`\r\n",
        " * 10, 12, 100 : `number`\r\n",
        " * ㅋ, ㅋㅋㅋㅋ, ㅋㅋㅋㅋㅋㅋㅋ : `ㅋㅋ`\r\n",
        "* 대소문자 통합 등"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZCRzaq9Jf72"
      },
      "source": [
        "# Tokenization 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baHKD-za6Kz1",
        "outputId": "35f55bb4-af1e-4e03-e7b3-e295ac115e0d"
      },
      "source": [
        "# 영어는 보통 nptk 패키지에 준비가 되어 있는 것이 많다\r\n",
        "# pip install nltk로 설치\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt') # 영어 토크나이져 패키지 다운로드\r\n",
        "sentence = \"Ain't nothin' sweeter, you want this sugar, don't ya?\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruKhogovKNYo"
      },
      "source": [
        "## [English] 기본 토크나이저"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLfiB_r-6K51",
        "outputId": "bdc14b78-650f-4797-c455-b7ab0fc0f963"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\r\n",
        "print(word_tokenize(sentence))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP4gB8nBKRVe"
      },
      "source": [
        "## [English] WordPunkTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7E1nAXm6K_9",
        "outputId": "05790ba6-1359-4e9c-ecb7-427a62acd423"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\r\n",
        "print(WordPunctTokenizer().tokenize(sentence))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ain', \"'\", 't', 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'don', \"'\", 't', 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkf-FkVNKhrV"
      },
      "source": [
        "## [English] TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uaseNSj6LFh",
        "outputId": "dea3c625-5e1e-44d0-c8ed-db06b12ba9d2"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\r\n",
        "tokenizer = TreebankWordTokenizer()\r\n",
        "print(tokenizer.tokenize(sentence))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AelwuByS6LLV",
        "outputId": "0f54d4e4-0fbc-4f5c-b7e2-b7a7a474c45b"
      },
      "source": [
        "# TreebankWordTokenizer는 하이푼이 있는 단어를 하나로 묶을 수 있다.\r\n",
        "print(tokenizer.tokenize(\"i'm Iron-man\"))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', \"'m\", 'Iron-man']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-MLtJ4OLNaU"
      },
      "source": [
        "# 한국어 토크나이저 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ4itQS-6LQ4"
      },
      "source": [
        "from konlpy.tag import Hannanum # 한나눔\r\n",
        "from konlpy.tag import Kkma # 꼬꼬마\r\n",
        "from konlpy.tag import Komoran # 코모란\r\n",
        "from konlpy.tag import Okt # 트위터 \r\n",
        "from konlpy.tag import Mecab # 거의 대부분 사용하는 토크나이저\r\n",
        "hannanum = Hannanum()\r\n",
        "kkma = Kkma()\r\n",
        "komoran = Komoran()\r\n",
        "okt = Okt()\r\n",
        "mecab = Mecab()\r\n",
        "sentence = \"좋으니 그 사람 솔직히 견디기 버거워\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s71zzj5LL2ia"
      },
      "source": [
        "def print_tokenization(tokenizer):\r\n",
        "  print(tokenizer.nouns(sentence)) # 명사만 추출\r\n",
        "  print(tokenizer.morphs(sentence)) # 각 형태소 별로 토큰화\r\n",
        "  print(tokenizer.pos(sentence)) # 각 형태소 토큰 및 형태소 종류를 튜플로 표시"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJEvYwiwLy0Q"
      },
      "source": [
        "## 트위터 (Okt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAKftsMH6LXO",
        "outputId": "78713796-bd41-4a85-c52e-67265188273f"
      },
      "source": [
        "print_tokenization(okt)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['그', '사람']\n",
            "['좋으니', '그', '사람', '솔직히', '견디기', '버거워']\n",
            "[('좋으니', 'Adjective'), ('그', 'Noun'), ('사람', 'Noun'), ('솔직히', 'Adjective'), ('견디기', 'Verb'), ('버거워', 'Adjective')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAedyDg2NTtY"
      },
      "source": [
        "## 꼬꼬마(kkma)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m67x609OLvhp",
        "outputId": "bfc7b4bd-e298-4198-90ac-79bac8829052"
      },
      "source": [
        "print_tokenization(kkma)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버겁', '어']\n",
            "[('좋', 'VA'), ('으니', 'ECD'), ('그', 'MDT'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버겁', 'VA'), ('어', 'ECS')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99fvdkp2NWUI"
      },
      "source": [
        "## 코모란 (komoran)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB08SjNqLvqZ",
        "outputId": "e44673bd-c62c-498e-9bad-985831505c0b"
      },
      "source": [
        "print_tokenization(komoran)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
            "[('좋', 'VA'), ('으니', 'EC'), ('그', 'MM'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버거워', 'NA')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf8QMTfINjiO"
      },
      "source": [
        "# 한나눔 (Hannanum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd8GEs21Lvxg",
        "outputId": "636141a5-0272-4d4e-fce7-f74758efdbdc"
      },
      "source": [
        "print_tokenization(hannanum)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람', '버거워']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
            "[('좋', 'P'), ('으니', 'E'), ('그', 'M'), ('사람', 'N'), ('솔직히', 'M'), ('견디', 'P'), ('기', 'E'), ('버거워', 'N')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Pp1BymNsIe"
      },
      "source": [
        "## 메캅 (Mecab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKxP3W0_Lv4P",
        "outputId": "3f00f71c-98da-45c0-9e2b-bcd5ffd483ac"
      },
      "source": [
        "print_tokenization(mecab)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
            "[('좋', 'VA'), ('으니', 'EC'), ('그', 'MM'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버거워', 'VA+EC')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIfbxgvBOCkU"
      },
      "source": [
        "## 문장 토크나이징\r\n",
        "\r\n",
        "단순히 물음표나 온점(.), 느낌표 등으로 문장을 잘라내면 문장 토크나이징 일까요?\r\n",
        "> 니 아이피가 192.168.56.21 맞니?\r\n",
        "\r\n",
        "> looking for Ph.D. Students"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oURVnEd1OhR3"
      },
      "source": [
        "## [English] sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn_zD4NELwHp",
        "outputId": "5479b1c5-5ae1-49de-f567-c7218bb90ef1"
      },
      "source": [
        "text = \"Since I'm actively looking for Ph.D. students. I get the same question a dozen times every year.\"\r\n",
        "\r\n",
        "from nltk.tokenize import sent_tokenize\r\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Since I'm actively looking for Ph.D. students.\", 'I get the same question a dozen times every year.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4mcAgdbLwNx"
      },
      "source": [
        "text = \"My IP Address is 192.168.56.51. Hello World!\""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olBJGAgEO2Ch",
        "outputId": "b5fae261-a7d0-4427-e117-e9a57346f6a9"
      },
      "source": [
        "print(sent_tokenize(text))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['My IP Address is 192.168.56.51.', 'Hello World!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eKfpHZOPBaG"
      },
      "source": [
        "## [Korean] kss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXhXTKF4O4kA"
      },
      "source": [
        "# !pip install kss"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDS-lfqgO770",
        "outputId": "0516d78d-3087-450a-e567-f4d88fb762be"
      },
      "source": [
        "import kss\r\n",
        "\r\n",
        "text = \"제 아이피는 192.168.56.21 이에요. 자연어 처리가 재미있나요?ㅋㅋ 딥러닝 들어가면 뚝배기가 아파와요\"\r\n",
        "\r\n",
        "print(kss.split_sentences(text))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['제 아이피는 192.168.56.21 이에요.', '자연어 처리가 재미있나요?ㅋㅋ', '딥러닝 들어가면 뚝배기가 아파와요']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGCMc7yRPvQ4"
      },
      "source": [
        "## [Korean] 띄어쓰기 및 맞춤법 정리\r\n",
        "### KoSpacing\r\n",
        "### Hanspell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL5tO5mNO726"
      },
      "source": [
        "# !pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUASg35xO70n"
      },
      "source": [
        "# !pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsUgAQ7YO7yV"
      },
      "source": [
        "from hanspell import spell_checker\r\n",
        "from pykospacing import spacing"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2f0BIUSQbPG"
      },
      "source": [
        "## KoSpacing 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKZgJMNVO7wS",
        "outputId": "d12dd466-0121-416d-84a2-e38ccd237baa"
      },
      "source": [
        "text = \"4번놀고있지.4번은팀워크가없어.4번은개인주의야.4번은혼자밖에생각하지않아.\"\r\n",
        "spacing_text = spacing(text)\r\n",
        "print(spacing_text)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4번 놀고 있지.4번은 팀워크가 없어.4번은 개인주의야.4번은 혼자 밖에 생각하지 않아.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTC-LJTWQ0hG"
      },
      "source": [
        "Hanspell 사용하기\r\n",
        "- 맞춤법 검사 및 교정\r\n",
        "- KoSpacing 처럼 띄어쓰기 교정도 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678B4aPaO7eC",
        "outputId": "d22fd326-7126-4746-d6e8-9b031c89d7ed"
      },
      "source": [
        "hanspell_text = spell_checker.check(text).checked\r\n",
        "print(hanspell_text)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4번 놀고 있지. 4번은 팀워크가 없어. 4번은 개인주의야. 4번은 혼자밖에 생각하지 않아.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyO7KNDyO7at",
        "outputId": "d45cd7e9-e13c-4c21-a8a9-01ee24cfec2f"
      },
      "source": [
        "text = '맞춤뻡 틀리면 외 않되?'\r\n",
        "\r\n",
        "hanspell_text = spell_checker.check(text).checked\r\n",
        "print(hanspell_text)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "맞춤법 틀리면 왜 안돼?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR2CQm3DVBmi"
      },
      "source": [
        "## 텍스트 정규화\r\n",
        "\r\n",
        "문장의 복잡도를 낮추는 과정, 복잡도가 낮아지기 때문에 처리할 단어가 줄어든다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLdWvsGXVK8u"
      },
      "source": [
        "### [English] 정규화 - Stemming 과정\r\n",
        "어간(stem)을 추출하는 과정 - 영어에서는 사전에 없는 이상한 단어가 나오는 경우가 종종 있습니다.\r\n",
        "\r\n",
        "* Serialize : serial\r\n",
        "* Medical : medic\r\n",
        "* allowance : allow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7UqErTAO7Xr"
      },
      "source": [
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "\r\n",
        "porter_stemmer = PorterStemmer()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWEEpquHVvlN",
        "outputId": "5e880b21-ddfe-445c-9407-6ca9bad67cd9"
      },
      "source": [
        "text = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\r\n",
        "\r\n",
        "words = word_tokenize(text)\r\n",
        "print(words)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bnDNjpyVxEA",
        "outputId": "a4de2aac-fc57-4e9e-dd18-343a84937821"
      },
      "source": [
        "# stemmer 활용하기 위해서는 문장이 단어 토큰화 되어 있어야 한다.\r\n",
        "print([porter_stemmer.stem(w) for w in words])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apNw7XBkWuLh"
      },
      "source": [
        "### [Korean] 정규화 - Okt 활용 (Stemming, Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cvn5LLAWCj4",
        "outputId": "e90a834b-683a-4489-c375-7555bb9f97b0"
      },
      "source": [
        "okt = Okt()\r\n",
        "\r\n",
        "text = \"4번 놀고 있지. 4번은 팀워크가 없어. 4번은 개인주의야. 4번은 혼자밖에 생각하지 않아.\"\r\n",
        "print(okt.morphs(text)) # 일반 형태소 분리\r\n",
        "print(okt.morphs(text, stem=True)) # 어간이 추출된 형태소 분리"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['4', '번', '놀고', '있지', '.', '4', '번은', '팀워크', '가', '없어', '.', '4', '번은', '개인주의', '야', '.', '4', '번은', '혼자', '밖에', '생각', '하지', '않아', '.']\n",
            "['4', '번', '놀다', '있다', '.', '4', '번은', '팀워크', '가', '없다', '.', '4', '번은', '개인주의', '야', '.', '4', '번은', '혼자', '밖에', '생각', '하다', '않다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC_mqk0tXFHD",
        "outputId": "564adf9c-87a7-4c5e-c137-ef701c7ee567"
      },
      "source": [
        "print(okt.pos(text))\r\n",
        "print(okt.pos(text,stem=True))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('4', 'Number'), ('번', 'Noun'), ('놀고', 'Verb'), ('있지', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('팀워크', 'Noun'), ('가', 'Josa'), ('없어', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('개인주의', 'Noun'), ('야', 'Josa'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('혼자', 'Noun'), ('밖에', 'Josa'), ('생각', 'Noun'), ('하지', 'Verb'), ('않아', 'Verb'), ('.', 'Punctuation')]\n",
            "[('4', 'Number'), ('번', 'Noun'), ('놀다', 'Verb'), ('있다', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('팀워크', 'Noun'), ('가', 'Josa'), ('없다', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('개인주의', 'Noun'), ('야', 'Josa'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('혼자', 'Noun'), ('밖에', 'Josa'), ('생각', 'Noun'), ('하다', 'Verb'), ('않다', 'Verb'), ('.', 'Punctuation')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aunVaIS-XxT9"
      },
      "source": [
        "text = '웃기는 소리하지마랔ㅋㅋㅋㅋㅋ알았짛ㅎㅎㅎ'"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMLAXjMAYAvr",
        "outputId": "37361530-5179-4cf1-8fff-fd97fde9d0e1"
      },
      "source": [
        "print(okt.morphs(text))\r\n",
        "print(okt.morphs(text, norm=True)) "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['웃기는', '소리', '하지마', '랔', 'ㅋㅋㅋㅋㅋ', '알았짛', 'ㅎㅎㅎ']\n",
            "['웃기는', '소리', '하지마라', 'ㅋㅋㅋ', '알았지', 'ㅎㅎㅎ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ChUCkc1YAtU",
        "outputId": "9980f79c-b7b6-430e-fc91-1436c78ba5d7"
      },
      "source": [
        "print(okt.morphs(text, norm=True, stem=True))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['웃기다', '소리', '하다', 'ㅋㅋㅋ', '알다', 'ㅎㅎㅎ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-4FfpxGYcW7"
      },
      "source": [
        "## [Korean] 이모티콘이나 의미없이 반복되는 문자 정제\r\n",
        "- ㅋㅋ,ㅋㅋㅋㅋㅋ,ㅋㅋㅋㅋㅋㅋㅋㅋ\r\n",
        "- 히히,호호.크크뤀크크\r\n",
        "\r\n",
        "이모티콘이나 의미없이 반복되는 문자들을 정제 하기 위한 패키지\r\n",
        "\r\n",
        "!pip install soynlp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge2rrfqaYAYl"
      },
      "source": [
        "# !pip install soynlp"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHL1Yud4YAWb",
        "outputId": "fb86b157-31b7-47d2-c1b9-f5657a69a1e7"
      },
      "source": [
        "from soynlp.normalizer import emoticon_normalize\r\n",
        "\r\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠ',num_repeats=2))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "아ㅋㅋ영화존잼쓰ㅠㅠㅠ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehpr5KMQZugu"
      },
      "source": [
        "## 텍스트 정제 (Cleaning)\r\n",
        "\r\n",
        "* 정규식을 이용한 정제 방법\r\n",
        " * 특수기호나 의미 없는 공백등을 정규식을 활용해서 제거하는 작업\r\n",
        "\r\n",
        "* 불용어(stopwords) 정제\r\n",
        " * 빈도수가 낮거나, 의미 없는 단어를 문장에서 제거하는 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIW1lplGYAUY",
        "outputId": "b21ee238-0f50-41ba-bdfa-4c3865ba8eae"
      },
      "source": [
        "import re\r\n",
        "eng_sent = \"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\"\r\n",
        "print(eng_sent)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Yeah, do you expect people to read the FAQ, etc. and actually accept hard\n",
            "atheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\n",
            "of steam!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jim,\n",
            "\n",
            "Sorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\n",
            "denial about the faith you need to get by.  Oh well, just pretend that it will\n",
            "all end happily ever after anyway.  Maybe if you start a new newsgroup,\n",
            "alt.atheist.hard, you won't be bummin' so much?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \n",
            "--\n",
            "Bake Timmons, III\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN04Q_DeYASJ",
        "outputId": "12c32f29-f8ed-446c-9e89-8a82fcaf9070"
      },
      "source": [
        "# sub : replace 와 같은 역할\r\n",
        "\r\n",
        "eng_sent = re.sub('[^a-zA-z]', \" \", eng_sent)\r\n",
        "print(eng_sent)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Yeah  do you expect people to read the FAQ  etc  and actually accept hard atheism   No  you need a little leap of faith  Jimmy   Your logic runs out of steam         Jim   Sorry I can t pity you  Jim   And I m sorry that you have these feelings of denial about the faith you need to get by   Oh well  just pretend that it will all end happily ever after anyway   Maybe if you start a new newsgroup  alt atheist hard  you won t be bummin  so much        Bye Bye  Big Jim   Don t forget your Flintstone s Chewables          Bake Timmons  III\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz7UqN4HYAQN"
      },
      "source": [
        "# 4글자 이상인 단어만 추출해서 새롭게 문장을 만들기\r\n",
        "\r\n",
        "eng_sent = ' '.join([ i for i in eng_sent.split() if len(i) >=4 ])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP38HA6Pc_M4"
      },
      "source": [
        "## 한국어 정규 표현식 정제\r\n",
        "한국어 문장에서 한글만 추출하는 정규식 표현 : [ㄱ-ㅎㅏ-ㅣ가-힐]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xlvT-3KcYAI6",
        "outputId": "f51e7d93-3438-48e2-b143-813c999ae452"
      },
      "source": [
        "kor_sent = \"와 이런 것도 영화라고....ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔!!\"\r\n",
        "kor_sent"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'와 이런 것도 영화라고....ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔!!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-ea5N--ddPiZ",
        "outputId": "a3051bd5-ea9a-4048-c751-7e6ff34afdaf"
      },
      "source": [
        "kor_sent = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\",\" \",kor_sent)\r\n",
        "kor_sent"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'와 이런 것도 영화라고    ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "125LB6m_deJI",
        "outputId": "73e23e39-2556-49d4-e51c-502bcda6d92a"
      },
      "source": [
        "kor_sent = re.sub(\"[ ]{2,}\",\" \",kor_sent)\r\n",
        "kor_sent"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'와 이런 것도 영화라고 ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKMAbRLxduQI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}